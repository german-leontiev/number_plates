{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb2f0ed5-4230-433b-96b9-cb5aa027f6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path as p\n",
    "from glob import glob\n",
    "import json\n",
    "import shutil as sh\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "from PIL import Image as I\n",
    "from matplotlib import pyplot as plt\n",
    "import imagesize\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6466d30a-fc3a-4b6b-8ebb-f0730c43213c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root_dir = \"custom_dataset\"\n",
    "sh.rmtree(dataset_root_dir)\n",
    "train_images_dir = \"images/train\"\n",
    "val_images_dir = \"images/val\"\n",
    "test_images_dir = \"images/test\"\n",
    "\n",
    "p.mkdir(p(dataset_root_dir), exist_ok=True, parents=True)\n",
    "\n",
    "for path in [train_images_dir, val_images_dir, test_images_dir]:\n",
    "    p.mkdir(p(dataset_root_dir) / path, exist_ok=True, parents=True)\n",
    "\n",
    "yaml_content = f\"\"\"\n",
    "path: ../{dataset_root_dir} \n",
    "train: {train_images_dir} \n",
    "val: {val_images_dir}\n",
    "test:  {test_images_dir}\n",
    "names:\n",
    "  0: dummy\n",
    "  1: plate\n",
    "\"\"\"\n",
    "\n",
    "with open(\"custom_dataset.yaml\", \"w\") as f:\n",
    "    f.write(yaml_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc756319-7f2c-4f96-8b23-720a3bdcb12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9044/9044 [05:19<00:00, 28.28it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2261/2261 [01:05<00:00, 34.49it/s]\n"
     ]
    }
   ],
   "source": [
    "source_dataset = \"nomeroff_datasets/autoriaNumberplateDataset-2022-08-01/\"\n",
    "for subset in [\"train\", \"val\"]:\n",
    "    all_images_paths = [\n",
    "        path\n",
    "        for path in glob(\n",
    "            f\"nomeroff_datasets/autoriaNumberplateDataset-2022-08-01/{subset}/*\"\n",
    "        )\n",
    "        if \".json\" not in path and \".sh\" not in path\n",
    "    ]\n",
    "    annotations_path = [\n",
    "        path\n",
    "        for path in glob(\n",
    "            f\"nomeroff_datasets/autoriaNumberplateDataset-2022-08-01/{subset}/*\"\n",
    "        )\n",
    "        if \".json\" in path\n",
    "    ][0]\n",
    "    with open(annotations_path, \"r\") as f:\n",
    "        annotation = json.loads(f.read())\n",
    "    ann_dir = dataset_root_dir + \"/\" + f\"labels/{subset}\" + \"/\"\n",
    "\n",
    "    p.mkdir(p(ann_dir), parents=True, exist_ok=True)\n",
    "\n",
    "    nr = [\n",
    "        (fn[\"filename\"], fn[\"regions\"])\n",
    "        for fn in list(annotation[\"_via_img_metadata\"].values())\n",
    "    ]\n",
    "    for filename, regions in tqdm(nr):\n",
    "\n",
    "        s = source_dataset + subset + \"/\" + filename\n",
    "        d = dataset_root_dir + \"/\" + f\"images/{subset}\" + \"/\" + filename\n",
    "        sh.copy(s, d)\n",
    "        image_width, image_height = imagesize.get(s)\n",
    "        ann_content = \"\"\n",
    "        for region in regions:\n",
    "            shape_attributes = region[\"shape_attributes\"]\n",
    "            if shape_attributes[\"name\"] == \"polygon\":\n",
    "                all_points_x = region[\"shape_attributes\"][\"all_points_x\"]\n",
    "                all_points_y = region[\"shape_attributes\"][\"all_points_y\"]\n",
    "                width = (max(all_points_x) - min(all_points_x)) / image_width\n",
    "                height = (max(all_points_y) - min(all_points_y)) / image_height\n",
    "\n",
    "                x_center = min(all_points_x) / image_width + width / 2\n",
    "                y_center = min(all_points_y) / image_height + height / 2\n",
    "\n",
    "                ann_content += \"1 {:.6f} {:.6f} {:.6f} {:.6f}\\n\".format(\n",
    "                    x_center, y_center, width, height\n",
    "                )\n",
    "\n",
    "        basename = \".\".join(filename.split(\".\")[:-1])\n",
    "        txt_save_path = ann_dir + basename + \".txt\"\n",
    "\n",
    "        with open(txt_save_path, \"w\") as f:\n",
    "            f.write(ann_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d30b761f-358c-4424-923e-4928a96f21eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=custom_dataset.yaml, hyp=yolov5/data/hyps/hyp.scratch-low.yaml, epochs=30, batch_size=8, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=., name=yolov5s_train, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 âœ…\n",
      "YOLOv5 ðŸš€ v6.2-159-gd669a74 Python-3.8.13 torch-1.12.1 CUDA:0 (NVIDIA GeForce RTX 2070 SUPER, 8192MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 ðŸš€ runs in Weights & Biases\n",
      "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 ðŸš€ in ClearML\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 ðŸš€ runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir .', view at http://localhost:6006/\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     18879  models.yolo.Detect                      [2, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "Model summary: 214 layers, 7025023 parameters, 7025023 gradients, 16.0 GFLOPs\n",
      "\n",
      "Transferred 343/349 items from yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/mnt/e/projects/itmo/deep_learning/number_plates/custom_dataset\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /mnt/e/projects/itmo/deep_learning/number_plates/custom_dataset/labels/train.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/mnt/e/projects/itmo/deep_learning/number_plates/custom_dataset/l\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /mnt/e/projects/itmo/deep_learning/number_plates/custom_dataset/labels/val.cache\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.70 anchors/target, 0.996 Best Possible Recall (BPR). Current anchors are a good fit to dataset âœ…\n",
      "Plotting labels to yolov5s_train/labels.jpg... \n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1myolov5s_train\u001b[0m\n",
      "Starting training for 30 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       0/29      1.98G    0.06262    0.01543   0.004572          6        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2261       2393      0.935      0.894      0.938      0.546\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       1/29      2.79G    0.04081   0.009165   0.001268          7        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2261       2393      0.972      0.929      0.961      0.589\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       2/29      2.79G    0.03598   0.007266   0.001127          9        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2261       2393      0.974      0.946      0.971      0.663\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       3/29      2.79G    0.03113   0.006401  0.0008937          3        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2261       2393      0.974      0.948      0.973      0.719\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       4/29      2.79G     0.0279   0.005982  0.0007006         10        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2261       2393       0.98      0.943      0.975      0.711\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       5/29      2.79G    0.02497   0.005578  0.0005418         11        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2261       2393      0.978      0.955      0.979      0.759\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       6/29      2.79G    0.02326   0.005297  0.0004505          5        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2261       2393      0.974      0.949      0.979      0.774\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       7/29      2.79G    0.02173   0.005182  0.0003873          8        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2261       2393      0.987      0.949      0.981      0.779\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       8/29      2.79G    0.02104   0.004979  0.0003462          9        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2261       2393      0.988      0.955      0.983       0.79\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       9/29      2.79G     0.0199   0.004872  0.0003127          8        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2261       2393       0.99      0.957      0.984      0.789\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      10/29      2.79G    0.01928    0.00463  0.0002773          6        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2261       2393      0.983      0.964      0.984      0.802\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      11/29      2.79G    0.01867   0.004632  0.0002607          7        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2261       2393      0.985      0.961      0.984      0.806\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      12/29      2.79G    0.01822   0.004581  0.0002417          4        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2261       2393      0.988      0.958      0.984      0.806\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      13/29      2.79G    0.01777   0.004544  0.0002206          7        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2261       2393      0.987      0.959      0.984      0.816\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      14/29      2.79G    0.01713   0.004392  0.0002052          7        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2261       2393      0.989      0.957      0.985      0.816\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      15/29      2.79G    0.01674   0.004353  0.0001938          7        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2261       2393      0.991      0.958      0.984      0.819\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      16/29      2.79G    0.01635   0.004255  0.0001744          7        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2261       2393      0.988       0.96      0.987       0.83\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      17/29      2.79G    0.01582    0.00419  0.0001594          9        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2261       2393      0.994      0.956      0.986       0.83\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      18/29      2.79G    0.01553   0.004117  0.0001506          7        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2261       2393      0.991       0.96      0.986      0.834\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      19/29      2.79G    0.01526     0.0041  0.0001411          8        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2261       2393       0.99      0.962      0.986      0.833\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      20/29      2.79G     0.0149   0.003937  0.0001289          6        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2261       2393      0.984      0.966      0.987      0.837\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      21/29      2.79G    0.01453    0.00397  0.0001205          7        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2261       2393      0.991      0.959      0.987       0.84\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      22/29      2.79G    0.01432   0.003843   0.000111          7        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2261       2393      0.992      0.959      0.987       0.84\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      23/29      2.79G      0.014   0.003895  0.0001052          7        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2261       2393       0.99      0.959      0.988      0.845\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      24/29      2.79G    0.01364    0.00377  9.825e-05          7        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2261       2393      0.993      0.959      0.987      0.844\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      25/29      2.79G    0.01355    0.00375  9.138e-05          8        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2261       2393      0.992      0.958      0.988      0.845\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      26/29      2.79G    0.01318   0.003644  8.367e-05          8        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2261       2393      0.992      0.958      0.987      0.852\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      27/29      2.79G    0.01304   0.003643  8.144e-05          7        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2261       2393      0.991       0.96      0.988      0.851\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      28/29      2.79G    0.01278   0.003594  7.368e-05          8        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2261       2393       0.99      0.964       0.99      0.852\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      29/29      2.79G    0.01256   0.003592  6.988e-05          6        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2261       2393      0.992       0.96       0.99      0.854\n",
      "\n",
      "30 epochs completed in 1.645 hours.\n",
      "Optimizer stripped from yolov5s_train/weights/last.pt, 14.3MB\n",
      "Optimizer stripped from yolov5s_train/weights/best.pt, 14.3MB\n",
      "\n",
      "Validating yolov5s_train/weights/best.pt...\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7015519 parameters, 0 gradients, 15.8 GFLOPs\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2261       2393      0.992       0.96       0.99      0.854\n",
      "                 plate       2261       2393      0.992       0.96       0.99      0.854\n",
      "Results saved to \u001b[1myolov5s_train\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! python yolov5/train.py --img 640 --batch 8 --epochs 30 --data custom_dataset.yaml --weights yolov5s.pt --project . --name yolov5s_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f7aecc-8b2c-498e-a410-f64188c36f69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
